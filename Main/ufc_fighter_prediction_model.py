# -*- coding: utf-8 -*-
"""UFC_Fighter_prediction_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MQ2efLlzbntCzTJyOllwEHx9GD0IMI02

#**UFC Fight Outcome Prediction Using multi models**

##**Step 1: Install and Import Libraries**

- **Installation:** Start by installing necessary libraries using `pip install`. This ensures all required packages are available.

- **Imports:** Import libraries for data manipulation (`pandas`, `numpy`), visualization (`seaborn`, `matplotlib`), display (`IPython.display`), machine learning (`scikit-learn`), and specific models (`CatBoostClassifier`, `XGBClassifier`, etc.).
"""

# Install necessary libraries (if not already installed)
!pip install pandas numpy scikit-learn seaborn matplotlib catboost tensorflow

"""
Purpose: Import all necessary libraries for data manipulation, visualization, preprocessing, and machine learning models.

Variables:
    pd: Alias for pandas, used for data manipulation.
    np: Alias for numpy, used for numerical operations.
    sns: Alias for seaborn, used for data visualization.
    plt: Alias for matplotlib.pyplot, used for plotting graphs.
    Machine learning models and tools are imported from sklearn, catboost, and xgboost.
"""

# Import data manipulation libraries
import pandas as pd
import numpy as np

# Import visualization libraries
from IPython.display import display,  HTML
import seaborn as sns
import matplotlib.pyplot as plt

# Import machine learning libraries
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import  cross_val_score

# Import models
from sklearn.ensemble import RandomForestClassifier
from catboost import CatBoostClassifier
from xgboost import XGBClassifier

"""##**Step 2: Load and Prepare Data**

- **Loading Data:** You load the dataset `ufc-master.csv` into a pandas DataFrame called `original_df`.

- **Previewing Data:** Display the first few rows using `head()` to understand the structure of the dataset.
"""

"""
Purpose: Load the UFC dataset from a CSV file into a pandas DataFrame and preview the first few rows to understand the data structure.

Variables:
    original_df: The original DataFrame containing the loaded data.
"""

# Load from local directory if uploaded to Colab
original_df = pd.read_csv('ufc-master.csv')

# Preview the data
original_df.head()

"""##**Step 3: Data Cleaning and preparing**"""

"""
Purpose: Reload the dataset into a new DataFrame for cleaning, keeping the original data intact.

Variables:
    df: DataFrame used for data cleaning and preprocessing.
"""

# Load the original dataset again
df = pd.read_csv('ufc-master.csv')

"""###**3.1 Handle Missing Values**

- **Calculating Missing Percentages:** Calculate the percentage of missing values for each column to identify columns that need imputation.

- **Imputation:**
  - **Numerical Columns:** Missing values are filled with the mean of each column.
  - **Categorical Columns:** Missing values are filled with the mode (most frequent value) of each column.
- **Verification:** After imputation, you verify that there are no missing values left.
"""

"""
Purpose: Calculate and display the percentage of missing values in each column to identify columns that need imputation.

Variables:
    missing_percentages: Series containing the percentage of missing values per column.
    missing_table: DataFrame that tabulates columns and their missing percentages.
"""

# Calculate the percentage of missing values
missing_percentages = df.isnull().mean() * 100

# Create a DataFrame to display the results
missing_table = pd.DataFrame({
    'Column': missing_percentages.index,
    'Missing Percentage': missing_percentages.values
})

# Sort the table by missing percentage in descending order
missing_table = missing_table.sort_values(by='Missing Percentage', ascending=False)

# Display the table nicely in Jupyter Notebook
display(missing_table)

"""
Purpose:
    - Identify numerical and categorical columns for appropriate imputation.
    - Impute missing numerical values with the mean and categorical values with the mode.

Variables:
    numerical_cols: List of numerical column names.
    categorical_cols: List of categorical column names.
"""

# Identify numerical and categorical columns
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = df.select_dtypes(include=['object']).columns

# Impute numerical columns with mean
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

# Impute categorical columns with mode
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

"""
Purpose:
    - Verify that all missing values have been handled.

Variables:
    - missing_values: Series with the count of missing values per column.
    - missing_values_df: DataFrame for displaying missing values after imputation.
"""
missing_values = df.isnull().sum()

# Convert to a DataFrame for better display
missing_values_df = pd.DataFrame({
    "Column": missing_values.index,
    "Missing Values": missing_values.values
})

# Display the missing values as a table
display(HTML("<h3>Missing values after handling:</h3>"))
display(missing_values_df)

"""###**3.2 Encode Categorical Variables**

- **Label Encoding:** Categorical variables are converted into numerical format using `LabelEncoder`. This is necessary because most machine learning models require numerical input.
"""

"""
Purpose: Convert categorical variables into numerical format using Label Encoding.

Variables:
    - categorical_features: List of categorical column names to be encoded.
    - le: Instance of LabelEncoder.
    - df[col]: Each categorical column is transformed using Label Encoding.
"""

# Define categorical features to encode
categorical_features = ['RedFighter', 'BlueFighter', 'Location', 'Country','WeightClass', 'TitleBout', 'Gender',  'Winner',  'BlueStance',  'RedStance', 'BetterRank',  'Finish', 'FinishDetails', 'FinishRoundTime']

# Initialize LabelEncoder
le = LabelEncoder()

# Encode categorical features
for col in categorical_features:
    df[col] = le.fit_transform(df[col])

# Preview encode data
df.head()

"""###**3.3 Define Features and Targets**

- **Features (`x`):** Define the feature set by dropping unnecessary columns like `'Date'`, `'Winner'`, `'Finish'`, and `'FinishRound'`.

- **Targets (`y`):**
  - **`y_winner`:** The target variable for predicting the winner.
  - **`y_method`:** The target variable for predicting the method of victory.
  - **`y_round`:** The target variable for predicting the round in which the fight ends.
"""

"""
Purpose: Separate the dataset into features (X) and target variables (y_winner, y_method, y_round) for modeling.

Variables:
    - X: Features used for training the models.
    - y_winner: Target variable for predicting the winner.
    - y_method: Target variable for predicting the method of victory.
    - y_round: Target variable for predicting the round in which the fight ends, converted to integer.
"""

# Define features (exclude target and unnecessary columns)
X = df.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)

# Define targets
y_winner = df['Winner']
y_method = df['Finish']
y_round = pd.to_numeric(df['FinishRound'], errors='coerce').fillna(0).astype(int)

"""###**3.4 Map Data**

- **Creating Mappings:** Create mappings between the original text labels and the encoded numerical labels for `'Winner'`, `'Finish'`, and `'FinishRound'`.This is helpful for interpreting the model's predictions later.
"""

"""
Purpose: Create a mapping between the original text labels and the encoded numerical labels for the 'Winner' column.

Variables:
    - x_winner: Original 'Winner' column with text labels.
    - mapping_dict: Dictionary mapping text labels to numerical labels.
    - mapping_df: DataFrame displaying the mapping.

Repeat similar steps for x_method and x_round to create mappings for 'Finish' and 'FinishRound' columns.
"""

x_winner = original_df["Winner"]

# Create a mapping dictionary from x_winner (text) to y_winner (numeric)
mapping_dict = dict(zip(x_winner.unique(), y_winner.unique()))

# Convert the mapping dictionary to a DataFrame
mapping_df = pd.DataFrame(list(mapping_dict.items()), columns=["Winner (Text)", "Winner (Numeric)"])

# Display the mapping as a table
display(HTML("<h3>Mapping between 'Winner' text and numeric labels:</h3>"))
display(mapping_df)

x_method = original_df['Finish']

# Create a mapping dictionary from x_method (text) to y_method (numeric)
mapping_dict = dict(zip(x_method.unique(), y_method.unique()))

# Convert the mapping dictionary to a DataFrame
mapping_df = pd.DataFrame(list(mapping_dict.items()), columns=["Finish (Text)", "Finish (Numeric)"])

# Display the mapping as a table
display(HTML("<h3>Mapping between 'Finish' text and numeric labels:</h3>"))
display(mapping_df)

x_round = original_df['FinishRound']

# Create a mapping dictionary from x_round to y_round
mapping_dict = dict(zip(x_round.unique(), y_round.unique()))

# Convert the mapping dictionary to a DataFrame
mapping_df = pd.DataFrame(list(mapping_dict.items()), columns=["Finish Round (Original)", "Finish Round (Mapped)"])

# Display the mapping as a table
display(HTML("<h3>Mapping between 'FinishRound' text and numeric labels:</h3>"))
display(mapping_df)

"""##**Step 4: Split Data Based on Date**

###**4.1 Define Cut-off Dates**

- **Cut-off Dates:** Define `train_end_date` and `test_start_date` to split the dataset into training and testing sets based on dates.
"""

"""
Purpose: Define the dates to split the dataset into training and testing sets based on fights' dates.

Variables:
    - train_end_date: End date for the training dataset.
    - test_start_date: Start date for the testing dataset.
"""

# Define the cut-off date for training and testing
train_end_date = pd.to_datetime('2024-03-31')
test_start_date = pd.to_datetime('2024-04-01')

"""###**4.2 Split the Data**

- **Training Data:** All fights that occurred on or before March 31, 2024.
- **Testing Data:** All fights that occurred on or after April 1, 2024.
- **Data Summary:** Create a summary to show the number of records in each dataset.
"""

"""
Purpose: Split the DataFrame into training and testing sets based on the defined dates.

Variables:
    - df_train: Training dataset.
    - df_test: Testing dataset.
    - data_summary: DataFrame summarizing the number of records in each set.
"""

df['Date'] = pd.to_datetime(df['Date'])

# Create training data: fights up to March 31, 2024
df_train = df[df['Date'] <= train_end_date]
df_train_method = df[df['Date'] <= train_end_date]

# Create testing data: fights from April 1, 2024 onwards
df_test = df[df['Date'] >= test_start_date]
df_test_method = df[df['Date'] >= test_start_date]

# Create a summary DataFrame
data_summary = pd.DataFrame({
    'Dataset': ['Training', 'Testing'],
    'Number of Records': [len(df_train), len(df_test)]
})

# Display the summary as a table
display(data_summary)

"""###**4.3 Prepare Features and Targets for Training and Testing**

- **Selected Features:** Load a list of selected features from `selected_features_40.csv` to use in the model.

- **Training and Testing Sets:**
  - **Features:** `X_train`, `X_test`, `X_train_method`, `X_test_method`.
  - **Targets:** `y_train_winner`, `y_test_winner`, `y_train_method`, `y_test_method`, `y_train_round`, `y_test_round`.

- **Display Data:** Display the first few rows of the training and testing data to inspect them.
"""

"""
Purpose:
    - Load selected features to be used in the models.
    - Prepare the feature matrices (X_train, X_test) and target vectors (y_train_*, y_test_*) for both training and testing datasets.

Variables:
selected_features: DataFrame containing the selected features.
    - features_to_use: List of selected feature names.
    - X_train, X_test: Feature matrices for winner and round prediction.
    - X_train_method, X_test_method: Feature matrices for method prediction.
    - y_train_winner, y_test_winner: Target vectors for winner prediction.
    - y_train_method, y_test_method: Target vectors for method prediction.
    - y_train_round, y_test_round: Target vectors for round prediction.
"""

# Load the selected features CSV file
selected_features = pd.read_csv('selected_features_40.csv')

# Load the selected features
features_to_use = selected_features['Selected Features'].tolist()

# Features and targets for training data
X_train = df_train[features_to_use]
X_train_method = df_train_method.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)

y_train_winner = df_train['Winner']
y_train_method = df_train['Finish']
y_train_round = pd.to_numeric(df_train['FinishRound'], errors='coerce').fillna(0).astype(int)

# Features and targets for testing data
X_test = df_test[features_to_use]
X_test_method = df_test_method.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)

y_test_winner = df_test['Winner']
y_test_method = df_test['Finish']
y_test_round = pd.to_numeric(df_test['FinishRound'], errors='coerce').fillna(0).astype(int)

# Display the X training data
display(HTML("<h3>X Training Data:</h3>"))
X_train.head()

X_train_method.head()

# Display the X test data
display(HTML("<h3>X Test Data:</h3>"))
X_test.head()

X_test_method.head()

"""###**4.4 Scale Features**

- **Scaling:** Use `StandardScaler` to standardize features by removing the mean and scaling to unit variance. This is important for many machine learning algorithms that are sensitive to the scale of the data.
- **Transformation:** Fit the scaler on the training data and then transform both the training and testing data.
- **Conversion to DataFrame:** Scaled data is converted back to pandas DataFrames for easier handling and display.
"""

"""
Purpose: Standardize features by removing the mean and scaling to unit variance using StandardScaler.

Variables:
    - scaler, scaler_method: Instances of StandardScaler for different feature sets.
    - X_train_scaled, X_test_scaled: Scaled feature matrices for winner and round prediction.
    - X_train_method_scaled, X_test_method_scaled: Scaled feature matrices for method prediction.
"""

# Initialize scaler
scaler = StandardScaler()
scaler_method = StandardScaler()

# Fit the scaler to the training data
scaler.fit(X_train)
scaler_method.fit(X_train_method)

# Scale the features using the previously fitted scaler
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

X_train_method_scaled = scaler_method.transform(X_train_method)
X_test_method_scaled = scaler_method.transform(X_test_method)

# Convert scaled training data back to DataFrames
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)

# Display the scaled training DataFrames
display(HTML("<h3>Scaled Training Data:</h3>"))
display(X_train_scaled_df)

# Convert Method scaled training data back to DataFrames
X_train_method_scaled_df = pd.DataFrame(X_train_method_scaled, columns=X_train_method.columns)

# Display the Method scaled training DataFrames
display(HTML("<h3>Method Scaled Training Data:</h3>"))
display(X_train_method_scaled_df)

# Convert scaled test data back to DataFrames
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Display the scaled test DataFrames
display(HTML("<h3>Scaled Test Data:</h3>"))
display(X_test_scaled_df)

# Convert scaled training data back to DataFrames
X_test_method_scaled_df = pd.DataFrame(X_test_method_scaled, columns=X_test_method.columns)

# Display the scaled training DataFrames
display(HTML("<h3>Method Scaled test Data:</h3>"))
display(X_test_method_scaled_df)

"""##**Step 5: Load models training**

###**5.1 Winner Prediction Model**

- **Model Selection:** Use `CatBoostClassifier` for predicting the winner because it handles categorical variables well and is efficient.
- **Training:** The model is trained using the scaled training features and the winner target variable.
"""

"""
Purpose: Train a CatBoost classifier to predict the winner of the fight.

Variables:
    - winner_model: Instance of CatBoostClassifier with specified hyperparameters.
    - X_train_scaled: Scaled features for training.
    - y_train_winner: Target variable for winner prediction.
"""

# Initialize CatBoost Classifier for winner prediction
winner_model = CatBoostClassifier(depth=10, learning_rate=0.01, iterations=1000, verbose=0)

# Train the model
winner_model.fit(X_train_scaled, y_train_winner)

"""###**5.2 Method Prediction Model**

- **Model Selection:** Use `XGBClassifier` for predicting the method of victory due to its performance with multiclass classification problems.
- **Training:** The model is trained using the method training features and the method target variable.
"""

"""
Purpose: Train an XGBoost classifier to predict the method of victory.

Variables:

    - method_model: Instance of XGBClassifier with specified hyperparameters.
    - X_train_method_scaled: Scaled features for training method prediction.
    - y_train_method: Target variable for method prediction.
"""

# Initialize XGB Classifier for method prediction
method_model = XGBClassifier(max_depth=10, n_estimators=500, learning_rate=0.01, num_class=7, random_state=42)

# Train the model
method_model.fit(X_train_method_scaled, y_train_method)

"""###**5.3 Round Prediction Model**

- **Model Selection:** Use `RandomForestClassifier` for predicting the round because it is robust and handles overfitting well.
- **Training:** The model is trained using the scaled training features and the round target variable.
"""

"""
Purpose: Train a Random Forest classifier to predict the round in which the fight ends.

Variables:
    - round_model: Instance of RandomForestClassifier with specified hyperparameters.
    - X_train_scaled: Scaled features for training.
    - y_train_round: Target variable for round prediction.
"""

# Initialize Random Forest Classifier for round prediction
round_model = RandomForestClassifier(max_depth=10, random_state=42)

# Train the model
round_model.fit(X_train_scaled, y_train_round)

"""##**Step 6: Make Predictions**

###**6.1 Winner Predictions**

- **Predictions:** The trained winner model is used to predict the winners on the test set.
- **Probabilities:** Obtain the probabilities associated with each prediction, which can be useful for assessing confidence.
"""

"""
Purpose: Use the trained winner model to make predictions on the test set and obtain prediction probabilities.

Variables:
    - y_pred_winner: Predicted labels for the winner.
    - y_proba_winner: Probabilities associated with each class for the predictions.
    - winner_probs: Maximum probability for each prediction, indicating the model's confidence.
"""

# Predict winner labels
y_pred_winner = winner_model.predict(X_test_scaled)

# Predict winner probabilities
y_proba_winner = winner_model.predict_proba(X_test_scaled)
winner_probs = y_proba_winner.max(axis=1)

"""###**6.2 Method Predictions**

- **Predictions:** The trained method model predicts the method of victory on the test set.
- **Probabilities:** Probabilities for each method class are obtained.
"""

"""
Purpose: Use the trained method model to predict the method of victory on the test set.

Variables:
    - y_pred_method: Predicted labels for the method of victory.
    - y_proba_method: Probabilities associated with each method class.
    - method_probs: Maximum probability for each prediction.
"""

# Predict method labels
y_pred_method = method_model.predict(X_test_method_scaled)

# Predict method probabilities
y_proba_method = method_model.predict_proba(X_test_method_scaled)
method_probs = y_proba_method.max(axis=1)

"""###**6.3 Round Predictions**

- **Predictions:** The trained round model predicts the round in which the fight ends.
- **Probabilities:** Probabilities for each round class are obtained.
"""

"""
Purpose: Use the trained round model to predict the round in which the fight ends.

Variables:
    - y_pred_round: Predicted labels for the round.
    - y_proba_round: Probabilities associated with each round class.
    - round_probs: Maximum probability for each prediction.
"""

# Predict round labels
y_pred_round = round_model.predict(X_test_scaled)

# Predict round probabilities
y_proba_round = round_model.predict_proba(X_test_scaled)
round_probs = y_proba_round.max(axis=1)

"""##**Step 7: Evaluate the Models**

###**7.1 Winner Model Evaluations**

- **Accuracy:** The accuracy of the winner prediction model is calculated.
- **Classification Report:** A detailed report showing precision, recall, f1-score, and support for each class.
- **Confusion Matrix:** A heatmap visualization of the confusion matrix helps to see where the model is making correct and incorrect predictions.
"""

"""
Purpose:
    - Calculate and display the accuracy of the winner prediction model.
    - Generate and display a detailed classification report for the winner model.
    - Visualize the confusion matrix of the winner model to assess where the model is making correct and incorrect predictions.

Variables:
    - accuracy_winner: Accuracy score of the winner model.
    - report: Dictionary containing precision, recall, f1-score, and support for each class.
    - classification_df: DataFrame version of the classification report.
    - cm_winner: Confusion matrix array.
    - Plotting functions to display the heatmap.

Similar steps are repeated for Method Model Evaluations and Round Model Evaluation, calculating accuracy, generating classification reports, and plotting confusion matrices.
"""

# Accuracy
accuracy_winner = accuracy_score(y_test_winner, y_pred_winner)
#print(f"Winner Model Accuracy: {accuracy_winner:.2f}")
display(HTML(f"<h3>Winner Model Accuracy: {accuracy_winner:.2f}</h3>"))

# Convert classification report to DataFrame
report = classification_report(y_test_winner, y_pred_winner, output_dict=True)
classification_df = pd.DataFrame(report).transpose()

# Display Classification Report as a Table
#print("Winner Model Classification Report:")
display(HTML("<h3>Winner Model Classification Report:</h3>"))
display(classification_df)

# Confusion Matrix as a Heatmap
# Blue = 0 and Red =1
cm_winner = confusion_matrix(y_test_winner, y_pred_winner)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_winner, annot=True, fmt='d', cmap='Blues', xticklabels=["Blue", "Red"], yticklabels=["Blue", "Red"])
plt.title("Winner Prediction Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""###**7.2 Method Model Evaluations**

- **Accuracy:** The accuracy of the method prediction model is calculated.
- **Classification Report:** Detailed performance metrics for each method class.
- **Confusion Matrix:** Heatmap visualization to assess prediction errors between different methods.
"""

# Accuracy
accuracy_method = accuracy_score(y_test_method, y_pred_method)
display(HTML(f"<h3>Method Model Accuracy: {accuracy_method:.2f}</h3>"))

# Convert classification report to DataFrame
report_method = classification_report(y_test_method, y_pred_method, output_dict=True)
classification_method_df = pd.DataFrame(report_method).transpose()

# Display Classification Report as a Table
display(HTML("<h3>Method Model Classification Report:</h3>"))
display(classification_method_df)

# Confusion Matrix as a Heatmap
cm_method = confusion_matrix(y_test_method, y_pred_method)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_method, annot=True, fmt='d', cmap='Blues',
            xticklabels=["DQ", "KO/TKO",  "M-DEC", "NaN", "S-DEC", "SUB", "U-DEC"],
            yticklabels=["DQ", "KO/TKO",  "M-DEC", "NaN", "S-DEC", "SUB", "U-DEC"])
plt.title("Method Prediction Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""###**7.3 Round Model Evaluation**

- **Accuracy:** The accuracy of the round prediction model is calculated.
- **Classification Report:** Performance metrics for each round class.
- **Confusion Matrix:** Visualization to see how well the model predicts the correct round.
"""

# Accuracy
accuracy_round = accuracy_score(y_test_round, y_pred_round)
display(HTML(f"<h3>Round Model Accuracy: {accuracy_round:.2f}</h3>"))

# Convert classification report to DataFrame
report_round = classification_report(y_test_round, y_pred_round, output_dict=True)
classification_round_df = pd.DataFrame(report_round).transpose()

# Display Classification Report as a Table
display(HTML("<h3>Round Model Classification Report:</h3>"))
display(classification_round_df)

# Confusion Matrix as a Heatmap
cm_round = confusion_matrix(y_test_round, y_pred_round)
plt.figure(figsize=(8, 6))
sns.heatmap(cm_round, annot=True, fmt='d', cmap='Blues',
            xticklabels=["Round 1", "Round 2", "Round 3", "Round 4", "Round 5"],
            yticklabels=["Round 1", "Round 2", "Round 3", "Round 4", "Round 5"])
plt.title("Round Prediction Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""##**Step 8: Save and load models**

###**8.1 Save Models**

- **Model Persistence:** Saves models to disk to avoid retraining.
- **pickle.dump():** Serializes the model object.
"""

"""
Purpose: Save the trained models to disk using pickle for future use without retraining.

Variables:
    - f: File object for writing binary data.
    - 'winner_model.pkl', 'method_model.pkl', 'round_model.pkl': Filenames for the saved models.
"""

# Save the winner prediction model
with open('winner_model.pkl', 'wb') as f:
    pickle.dump(winner_model, f)

# Save the method prediction model
with open('method_model.pkl', 'wb') as f:
    pickle.dump(method_model, f)

# Save the round prediction model
with open('round_model.pkl', 'wb') as f:
    pickle.dump(round_model, f)

print("All models have been saved successfully.")

"""###**8.2 Load Models**

- **Model Restoration:** Allows us to use the trained models without retraining.
- **pickle.load():** Deserializes the model object.
"""

"""
Purpose: Load the saved models from disk using pickle.

Variables:
    - f: File object for reading binary data.
    - winner_model, method_model, round_model: Loaded model instances ready for use.
"""

# Load the winner prediction model
with open('winner_model.pkl', 'rb') as f:
    winner_model = pickle.load(f)

# Load the method prediction model
with open('method_model.pkl', 'rb') as f:
    method_model = pickle.load(f)

# Load the round prediction model
with open('round_model.pkl', 'rb') as f:
    round_model = pickle.load(f)

print("All models have been loaded successfully.")