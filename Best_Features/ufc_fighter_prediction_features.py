# -*- coding: utf-8 -*-
"""UFC_Fighter_prediction_Features.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/10k1LVD1Vf4LUmjLn8qdd5qnGdGNAu8lp

#**UFC Fight Outcome Prediction Using Random Forest**

##**Step 1: Install and Import Libraries**
"""

# Install necessary libraries (if not already installed)
!pip install pandas numpy scikit-learn seaborn matplotlib

# Import data manipulation libraries
import pandas as pd
import numpy as np

# Import visualization libraries
from IPython.display import display,  HTML
import seaborn as sns
import matplotlib.pyplot as plt

# Import machine learning libraries
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import LabelEncoder, StandardScaler

# Import the Random Forest model
from sklearn.ensemble import RandomForestClassifier

from sklearn.feature_selection import RFE

"""##**Step 2: Load and Prepare Data**"""

# Load from local directory if uploaded to Colab
original_df = pd.read_csv('ufc-master.csv')

# Preview the data
original_df.head()

"""##**Step 3: Data Cleaning and Feature Engineering**"""

# Load the original dataset again
df = pd.read_csv('ufc-master.csv')

"""###**3.1 Handle Missing Values**"""

# Calculate the percentage of missing values
missing_percentages = df.isnull().mean() * 100

# Create a DataFrame to display the results
missing_table = pd.DataFrame({
    'Column': missing_percentages.index,
    'Missing Percentage': missing_percentages.values
})

# Sort the table by missing percentage in descending order
missing_table = missing_table.sort_values(by='Missing Percentage', ascending=False)

# Display the table nicely in Jupyter Notebook
display(missing_table)

# Identify numerical and categorical columns
numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns
categorical_cols = df.select_dtypes(include=['object']).columns

# Impute numerical columns with mean
df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())

# Impute categorical columns with mode
for col in categorical_cols:
    df[col] = df[col].fillna(df[col].mode()[0])

# Verify Missing Values Are Handled
missing_values = df.isnull().sum()

# Convert to a DataFrame for better display
missing_values_df = pd.DataFrame({
    "Column": missing_values.index,
    "Missing Values": missing_values.values
})

# Display the missing values as a table
display(HTML("<b>Missing values after handling:</b>"))
display(missing_values_df)

"""###**3.2 Encode Categorical Variables**"""

# Define categorical features to encode
categorical_features = ['RedFighter', 'BlueFighter', 'Location', 'Country','WeightClass', 'TitleBout', 'Gender',  'Winner',  'BlueStance',  'RedStance', 'BetterRank',  'Finish', 'FinishDetails', 'FinishRoundTime']

# Initialize LabelEncoder
le = LabelEncoder()

# Encode categorical features
for col in categorical_features:
    df[col] = le.fit_transform(df[col])

# Preview encode data
df.head()

"""###**3.3 Define Features and Targets**"""

# Define features (exclude target and unnecessary columns)
X = df.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)

# Define targets
y_winner = df['Winner']
y_method = df['Finish']
y_round = pd.to_numeric(df['FinishRound'], errors='coerce').fillna(0).astype(int)

"""###**3.4 Correlation Analysis**"""

# Compute the correlation matrix, excluding non-numeric columns
corr_matrix = df.select_dtypes(include=np.number).corr()

# Extract correlations with the target variable 'Winner'
target_corr = corr_matrix['Winner'].sort_values(ascending=False)

# Display the correlations as a table
display(HTML("<b>Correlation of features with target variable 'Winner':</b>"))
target_corr_df = target_corr.reset_index().rename(columns={'index': 'Feature', 'Winner': 'Correlation'})
display(target_corr_df)

# Plot heatmap of the correlation matrix
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, cmap='coolwarm', center=0)
plt.title('Correlation Heatmap')
plt.show()

"""##**Step 4: Split Data Based on Date**

###**4.1 Define Cut-off Dates**
"""

# Define the cut-off date for training and testing
train_end_date = pd.to_datetime('2024-03-31')
test_start_date = pd.to_datetime('2024-04-01')

"""###**4.2 Split the Data**"""

df['Date'] = pd.to_datetime(df['Date'])

# Create training data: fights up to March 31, 2024
df_train = df[df['Date'] <= train_end_date]

# Create testing data: fights from April 1, 2024 onwards
df_test = df[df['Date'] >= test_start_date]

# Create a summary DataFrame
data_summary = pd.DataFrame({
    'Dataset': ['Training', 'Testing'],
    'Number of Records': [len(df_train), len(df_test)]
})

# Display the summary as a table
display(data_summary)

"""###**4.3 Prepare Features and Targets for Training and Testing**"""

# Features and targets for training data
X_train = df_train.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)
y_train_winner = df_train['Winner']
y_train_method = df_train['Finish']
y_train_round = pd.to_numeric(df_train['FinishRound'], errors='coerce').fillna(0).astype(int)

# Features and targets for testing data
X_test = df_test.drop(['Date', 'Winner', 'Finish', 'FinishRound'], axis=1)
y_test_winner = df_test['Winner']
y_test_method = df_test['Finish']
y_test_round = pd.to_numeric(df_test['FinishRound'], errors='coerce').fillna(0).astype(int)

# Display the X training data
display(HTML("<b>X Training Data:</b>"))
X_train.head()

# Display the X test data
display(HTML("<b>X Test Data:</b>"))
X_test.head()

"""###**4.4 Scale Features**"""

# Initialize scaler
scaler = StandardScaler()

# Fit the scaler to the training data
scaler.fit(X_train)

# Scale the features using the previously fitted scaler
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Convert scaled training data back to DataFrames
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)

# Display the scaled training DataFrames
display(HTML("<b>Scaled Training Data:</b>"))
display(X_train_scaled_df)

# Convert scaled test data back to DataFrames
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)

# Display the scaled test DataFrames
display(HTML("<b>Scaled Test Data:</b>"))
display(X_test_scaled_df)

"""##**Step 5: Model Training**

###**5.1 Winner Prediction Model**
"""

# Train the winner model
winner_model = RandomForestClassifier(random_state=42)
winner_model.fit(X_train_scaled, y_train_winner)

"""###**5.2 Feature Importance from Random Forest**"""

# Extract feature importances
importances = winner_model.feature_importances_
features = X_train.columns
feature_importance_df = pd.DataFrame({'Feature': features, 'Importance': importances})
feature_importance_df.sort_values(by='Importance', ascending=False, inplace=True)

# Define the list of feature counts you want to display
feature_counts = [20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80, 85]

# Create a dictionary to store the top features for each feature count
feature_table = {}

for count in feature_counts:
    # Select the top `count` features
    top_features = feature_importance_df.head(count)['Feature'].values
    # Store the features in the dictionary
    feature_table[count] = top_features

# Convert the dictionary to a DataFrame
feature_table_df = pd.DataFrame.from_dict(feature_table, orient='index').transpose()

# Display the table
display(HTML(f"<h3>Feature Importance Table:</h3>"))
display(feature_table_df)

"""
# Display plots for each feature count
for count in feature_counts:
    display(HTML(f"<h3>Top {count} Important Features for Winner Prediction:</h3>"))
    # Plot the top N feature importances
    plt.figure(figsize=(12, 8))
    sns.barplot(x='Importance', y='Feature', data=feature_importance_df.head(count))
    plt.title(f'Top {count} Important Features for Winner Prediction')
    plt.show()
"""

"""###**5.3 Retrain Model with Top Features**"""

# Initialize a dictionary to store accuracy for each feature count
accuracy_results = {}

for count in feature_counts:
    # Get the top `count` features
    top_features = feature_importance_df['Feature'].head(count).values

    # Update X_train and X_test with selected features using .loc[] for column selection
    X_train_top_scaled = X_train_scaled[:, X_train.columns.get_indexer(top_features)]
    X_test_top_scaled = X_test_scaled[:, X_test.columns.get_indexer(top_features)]

    # Retrain the model
    winner_model_top = RandomForestClassifier(random_state=42)
    winner_model_top.fit(X_train_top_scaled, y_train_winner)

    # Make predictions
    y_pred_winner_top = winner_model_top.predict(X_test_top_scaled)

    # Evaluate the model
    accuracy_winner_top = accuracy_score(y_test_winner, y_pred_winner_top)
    accuracy_results[count] = accuracy_winner_top

# Convert the accuracy results to a DataFrame for display
accuracy_df = pd.DataFrame(list(accuracy_results.items()), columns=['Number of Features', 'Accuracy'])

# Display the results
accuracy_df.set_index('Number of Features', inplace=True)
display(accuracy_df)

"""###**5.4 Recursive Feature Elimination (RFE)**"""

# Define the list of feature counts you want to display
feature_counts_rfe = [40, 45, 50, 55, 60, 65, 70]

# Initialize lists to store results
rfe_results = []
features_dict = {}

for count in feature_counts_rfe:
    # Initialize RFE with the desired number of features
    rfe = RFE(estimator=RandomForestClassifier(random_state=42), n_features_to_select=count)
    rfe.fit(X_train_scaled, y_train_winner)

    # Get the selected features
    selected_features = X_train.columns[rfe.support_]
    features_dict[count] = selected_features  # Store features for this count

    # Update training and testing data
    X_train_rfe = X_train_scaled[:, rfe.support_]
    X_test_rfe = X_test_scaled[:, rfe.support_]

    # Retrain the model
    winner_model_rfe = RandomForestClassifier(random_state=42)
    winner_model_rfe.fit(X_train_rfe, y_train_winner)

    # Make predictions
    y_pred_winner_rfe = winner_model_rfe.predict(X_test_rfe)

    # Evaluate the model
    accuracy_winner_rfe = accuracy_score(y_test_winner, y_pred_winner_rfe)

    # Store the results
    rfe_results.append({
        'Number of Features': count,
        'Accuracy': accuracy_winner_rfe
    })

# Convert accuracy results to a DataFrame
rfe_results_df = pd.DataFrame(rfe_results)

# Convert features_dict to a DataFrame
features_df = pd.DataFrame.from_dict(features_dict, orient='index').transpose()

# Display the results
display(HTML(f"<h3>Accuracy Results:</h3>"))
display(rfe_results_df)

display(HTML(f"<h3>Selected Features:</h3>"))
display(features_df)

"""##**Step 6: Select and save best features**"""

# Select features calculated from RFE with 40 features
selected_features_40 = features_dict[40]

# Filter the original DataFrame to include only the selected features
filtered_df = original_df[selected_features_40]

# Save the filtered DataFrame to a CSV file
filtered_df.to_csv('filtered_data_40_features.csv', index=False)

# Save the selected feature names to a CSV file
pd.DataFrame(selected_features_40, columns=['Selected Features']).to_csv('selected_features_40.csv', index=False)

# Display the message with the number of features
display(HTML(f"<h3>Filtered DataFrame with {len(selected_features_40)} features saved as 'filtered_data_40_features.csv'</h3>"))
display(HTML(f"<h3>Selected feature names saved as 'selected_features_40.csv'</h3>"))

# Display the filtered DataFrame
display(filtered_df.head())